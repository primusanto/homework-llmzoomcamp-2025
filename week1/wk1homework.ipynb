{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "096c307c",
   "metadata": {},
   "source": [
    "**Q1. Running Elastic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb8e0f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: docker in ./.venv/lib/python3.13/site-packages (7.1.0)\n",
      "Requirement already satisfied: requests>=2.26.0 in ./.venv/lib/python3.13/site-packages (from docker) (2.32.3)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in ./.venv/lib/python3.13/site-packages (from docker) (2.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests>=2.26.0->docker) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.13/site-packages (from requests>=2.26.0->docker) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests>=2.26.0->docker) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "!pip install docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1c77314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import docker\n",
    "\n",
    "client = docker.from_env()\n",
    "\n",
    "container = client.containers.run(\n",
    "    image=\"docker.elastic.co/elasticsearch/elasticsearch:8.17.6\",\n",
    "    name=\"elasticsearch\",\n",
    "    environment={\n",
    "        \"discovery.type\": \"single-node\",\n",
    "        \"xpack.security.enabled\": \"false\"\n",
    "    },\n",
    "    mem_limit=\"4g\",\n",
    "    ports={'9200/tcp': 9200, '9300/tcp': 9300},\n",
    "    remove=True,\n",
    "    detach=True,\n",
    "    tty=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdeab2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The elastic search build hash is :  dbcbbbd0bc4924cfeb28929dc05d82d662c527b7\n"
     ]
    }
   ],
   "source": [
    "import requests, time\n",
    "\n",
    "time.sleep(5)\n",
    "response = requests.get(\"http://localhost:9200\")\n",
    "#print the build hash\n",
    "print(\"The elastic search build hash is : \",response.json()['version']['build_hash'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2874e4b3",
   "metadata": {},
   "source": [
    "**Q2. Indexing the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b36c0d",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd5dcbe",
   "metadata": {},
   "source": [
    "**Code for question 3 & 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18059e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: elasticsearch==8.18 in ./.venv/lib/python3.13/site-packages (8.18.0)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.13/site-packages (4.67.1)\n",
      "Requirement already satisfied: elastic-transport<9,>=8.15.1 in ./.venv/lib/python3.13/site-packages (from elasticsearch==8.18) (8.17.1)\n",
      "Requirement already satisfied: python-dateutil in ./.venv/lib/python3.13/site-packages (from elasticsearch==8.18) (2.9.0.post0)\n",
      "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.13/site-packages (from elasticsearch==8.18) (4.14.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.2 in ./.venv/lib/python3.13/site-packages (from elastic-transport<9,>=8.15.1->elasticsearch==8.18) (2.4.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.13/site-packages (from elastic-transport<9,>=8.15.1->elasticsearch==8.18) (2025.4.26)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil->elasticsearch==8.18) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install elasticsearch==8.18 tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca465d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking using python after running the above code\n",
    "#import elasticsearch & tqdm (progress bar)\n",
    "from elasticsearch import Elasticsearch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#assign the to es_client\n",
    "es_client = Elasticsearch('http://localhost:9200') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3426c888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': '5e6573ce33ee', 'cluster_name': 'docker-cluster', 'cluster_uuid': 'DyqpNDvEQW-kf5rBmldgZg', 'version': {'number': '8.17.6', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': 'dbcbbbd0bc4924cfeb28929dc05d82d662c527b7', 'build_date': '2025-04-30T14:07:12.231372970Z', 'build_snapshot': False, 'lucene_version': '9.12.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b1d125-e448-4434-b475-6b3198441c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting Data - store it in documents\n",
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9343b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 948/948 [00:04<00:00, 231.08it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#setting\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"course-questions\"\n",
    "\n",
    "#creating the index with the settings\n",
    "es_client.indices.create(index=index_name, body=index_settings)\n",
    "\n",
    "#indexing the documents\n",
    "for doc in tqdm(documents):\n",
    "    es_client.index(\n",
    "        index=index_name,\n",
    "        document=doc\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6b14dd",
   "metadata": {},
   "source": [
    "**Q3. Searching**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3ebb98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#defining the search query\n",
    "query= \"How do execute a command on a Kubernetes pod?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4f89dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top ranking result score: 44.50556\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#search query setting\n",
    "search_query = {\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^4\", \"text\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "#run the search\n",
    "response = es_client.search(index=index_name, body=search_query)\n",
    "result_docs = []\n",
    "\n",
    "#find out what we need\n",
    "for hit in response['hits']['hits']:\n",
    "    result_docs.append(hit['_score'])\n",
    "\n",
    "#find the top ranking result\n",
    "print(\"Top ranking result score:\", max(result_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cd4cf9",
   "metadata": {},
   "source": [
    "if es_client.indices.exists(index='course-questions'):\n",
    "    es_client.indices.delete(index='course-questions')\n",
    "    print(\"Index successfully deleted.\")\n",
    "else:\n",
    "    print(\"Index doesn't exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277d8084",
   "metadata": {},
   "source": [
    "**Q4. Filtering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7dfbaf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the search query\n",
    "query= \"How do copy a file to a Docker container?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "809123f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: How do I debug a docker container?\n",
      "Question 2: How do I copy files from my local machine to docker container?\n",
      "Question 3: How do I copy files from a different folder into docker container’s working directory?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#search query setting\n",
    "search_query = {\n",
    "        \"size\": 3,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^4\", \"text\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"course\": \"machine-learning-zoomcamp\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "#run the search\n",
    "response = es_client.search(index=index_name, body=search_query)\n",
    "result_docs = []\n",
    "\n",
    "#find out what we need\n",
    "for hit in response['hits']['hits']:\n",
    "    result_docs.append(hit['_source'])\n",
    "\n",
    "i=1\n",
    "for doc in result_docs:\n",
    "    print(f\"Question {i}: {doc['question']}\")\n",
    "    i += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dead6e23",
   "metadata": {},
   "source": [
    "**Q5. Building a prompt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afd1bdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How do I execute a command in a running docker container?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7b6b1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"Q:{doc['question']}\\nA:{doc['text']}\\n\\n\"\n",
    "    \n",
    "    context = context.strip()\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51a1d5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You\\'re a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\\nUse only the facts from the CONTEXT when answering the QUESTION.\\n\\nQUESTION: How do I execute a command in a running docker container?\\n\\nCONTEXT:\\nQ:How do I debug a docker container?\\nA:Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\\ndocker run -it --entrypoint bash <image>\\nIf the container is already running, execute a command in the specific container:\\ndocker ps (find the container-id)\\ndocker exec -it <container-id> bash\\n(Marcos MJD)\\n\\nQ:How do I copy files from my local machine to docker container?\\nA:You can copy files from your local machine into a Docker container using the docker cp command. Here\\'s how to do it:\\nTo copy a file or directory from your local machine into a running Docker container, you can use the `docker cp command`. The basic syntax is as follows:\\ndocker cp /path/to/local/file_or_directory container_id:/path/in/container\\nHrithik Kumar Advani\\n\\nQ:How do I copy files from a different folder into docker container’s working directory?\\nA:You can copy files from your local machine into a Docker container using the docker cp command. Here\\'s how to do it:\\nIn the Dockerfile, you can provide the folder containing the files that you want to copy over. The basic syntax is as follows:\\nCOPY [\"src/predict.py\", \"models/xgb_model.bin\", \"./\"]\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tGopakumar Gopinathan'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_result = build_prompt(query, result_docs)\n",
    "prompt_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dfe58955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1456"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompt_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bae5bff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: How do I debug a docker container?\n",
      "A: Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\n",
      "docker run -it --entrypoint bash <image>\n",
      "If the container is already running, execute a command in the specific container:\n",
      "docker ps (find the container-id)\n",
      "docker exec -it <container-id> bash\n",
      "(Marcos MJD)\n",
      "\n",
      "\n",
      "Q: How do I copy files from my local machine to docker container?\n",
      "A: You can copy files from your local machine into a Docker container using the docker cp command. Here's how to do it:\n",
      "To copy a file or directory from your local machine into a running Docker container, you can use the `docker cp command`. The basic syntax is as follows:\n",
      "docker cp /path/to/local/file_or_directory container_id:/path/in/container\n",
      "Hrithik Kumar Advani\n",
      "\n",
      "\n",
      "Q: How do I copy files from a different folder into docker container’s working directory?\n",
      "A: You can copy files from your local machine into a Docker container using the docker cp command. Here's how to do it:\n",
      "In the Dockerfile, you can provide the folder containing the files that you want to copy over. The basic syntax is as follows:\n",
      "COPY [\"src/predict.py\", \"models/xgb_model.bin\", \"./\"]\t\t\t\t\t\t\t\t\t\t\tGopakumar Gopinathan\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Q: How do I debug a docker container?\\nA: Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\\ndocker run -it --entrypoint bash <image>\\nIf the container is already running, execute a command in the specific container:\\ndocker ps (find the container-id)\\ndocker exec -it <container-id> bash\\n(Marcos MJD)\\n\\nQ: How do I copy files from my local machine to docker container?\\nA: You can copy files from your local machine into a Docker container using the docker cp command. Here\\'s how to do it:\\nTo copy a file or directory from your local machine into a running Docker container, you can use the `docker cp command`. The basic syntax is as follows:\\ndocker cp /path/to/local/file_or_directory container_id:/path/in/container\\nHrithik Kumar Advani\\n\\nQ: How do I copy files from a different folder into docker container’s working directory?\\nA: You can copy files from your local machine into a Docker container using the docker cp command. Here\\'s how to do it:\\nIn the Dockerfile, you can provide the folder containing the files that you want to copy over. The basic syntax is as follows:\\nCOPY [\"src/predict.py\", \"models/xgb_model.bin\", \"./\"]\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tGopakumar Gopinathan'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = \"\"\n",
    "for doc in result_docs:\n",
    "    print(f\"Q: {doc['question']}\\nA: {doc['text']}\\n\\n\")\n",
    "    context = context + f\"Q: {doc['question']}\\nA: {doc['text']}\\n\\n\"\n",
    "\n",
    "context = context.strip()\n",
    "context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ab8009",
   "metadata": {},
   "source": [
    "**Q6. Tokens**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "002c088d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Using cached tiktoken-0.9.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Using cached regex-2024.11.6-cp313-cp313-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in ./.venv/lib/python3.13/site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (2025.4.26)\n",
      "Using cached tiktoken-0.9.0-cp313-cp313-macosx_11_0_arm64.whl (1.0 MB)\n",
      "Using cached regex-2024.11.6-cp313-cp313-macosx_11_0_arm64.whl (284 kB)\n",
      "Installing collected packages: regex, tiktoken\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [tiktoken]\n",
      "\u001b[1A\u001b[2KSuccessfully installed regex-2024.11.6 tiktoken-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55bb68f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b46c4e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc2fe9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in the prompt: 322\n"
     ]
    }
   ],
   "source": [
    "#number of tokens in the prompt\n",
    "prompt_token = num_tokens_from_string(prompt_result, \"gpt-4o\")\n",
    "print(\"Number of tokens in the prompt:\", prompt_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42335eb",
   "metadata": {},
   "source": [
    "**Q7 Bonus: generating the answer (ungraded)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2583d535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.84.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Using cached jiter-0.10.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Using cached pydantic-2.11.5-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.13/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in ./.venv/lib/python3.13/site-packages (from openai) (4.14.0)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached pydantic_core-2.33.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Downloading openai-1.84.0-py3-none-any.whl (725 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m725.5/725.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached jiter-0.10.0-cp313-cp313-macosx_11_0_arm64.whl (318 kB)\n",
      "Using cached pydantic-2.11.5-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp313-cp313-macosx_11_0_arm64.whl (1.8 MB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-inspection, sniffio, pydantic-core, jiter, h11, distro, annotated-types, pydantic, httpcore, anyio, httpx, openai\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/12\u001b[0m [openai]11/12\u001b[0m [openai]c]\n",
      "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 anyio-4.9.0 distro-1.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 jiter-0.10.0 openai-1.84.0 pydantic-2.11.5 pydantic-core-2.33.2 sniffio-1.3.1 typing-inspection-0.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a0628ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d68c8808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "20a12426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To execute a command in a running Docker container, use the following command:\\n\\n```bash\\ndocker exec -it <container-id> bash\\n```\\n\\nFirst, you'll need to find the container ID of the running container by using the `docker ps` command. Once you have the container ID, you can replace `<container-id>` in the command above with the actual ID to execute the command inside the container.\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RUN AT YOUR COST\n",
    "answer = llm(prompt_result)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1aefa97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in the answer: 82\n"
     ]
    }
   ],
   "source": [
    "#number of tokens in the answer\n",
    "answer_token = num_tokens_from_string(answer, \"gpt-4o\")\n",
    "print(\"Number of tokens in the answer:\", answer_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fd6b2d",
   "metadata": {},
   "source": [
    "**Q8 Bonus: calculating the costs (ungraded)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63329884",
   "metadata": {},
   "source": [
    "On the 6th June 2025\n",
    "GPT 4.0 Text Cost\n",
    "\n",
    "$5.00 / 1M input token -> 0.00005c per token\n",
    "$20.00 / 1M output token -> 0.0002c per token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8380f931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt cost: $0.016100\n",
      "Answer cost: $0.016400\n"
     ]
    }
   ],
   "source": [
    "#prompt token cost\n",
    "prompt_cost = prompt_token * 0.05 / 1000\n",
    "#answer token cost\n",
    "answer_cost = answer_token * 0.2 / 1000\n",
    "\n",
    "print(f\"Prompt cost: ${prompt_cost:.6f}\")\n",
    "print(f\"Answer cost: ${answer_cost:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7486af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
